{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import (Activation, Concatenate, Conv2D,\n",
    "                                     Conv2DTranspose, Input, LeakyReLU)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "generator_g = tf.keras.models.load_model('generator_g.h5')\n",
    "generator_f = tf.keras.models.load_model('generator_f.h5')\n",
    "discriminator_x = tf.keras.models.load_model('discriminator_x.h5')\n",
    "discriminator_y = tf.keras.models.load_model('discriminator_y.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data, metadata = tfds.load('cycle_gan/monet2photo', with_info=True, as_supervised=True)\n",
    "\n",
    "train_x, train_y, test_x, test_y = data['trainA'], data['trainB'], data['testA'], data['testB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(256, 256, 3), dtype=uint8, numpy=\n",
       " array([[[111, 133, 146],\n",
       "         [109, 131, 144],\n",
       "         [105, 126, 143],\n",
       "         ...,\n",
       "         [ 51,  46,  50],\n",
       "         [ 44,  42,  45],\n",
       "         [ 78,  76,  79]],\n",
       " \n",
       "        [[112, 134, 148],\n",
       "         [106, 127, 144],\n",
       "         [ 99, 120, 139],\n",
       "         ...,\n",
       "         [ 44,  39,  43],\n",
       "         [ 40,  38,  41],\n",
       "         [ 64,  62,  65]],\n",
       " \n",
       "        [[113, 134, 155],\n",
       "         [105, 126, 147],\n",
       "         [ 94, 114, 138],\n",
       "         ...,\n",
       "         [ 37,  32,  36],\n",
       "         [ 37,  35,  38],\n",
       "         [ 46,  44,  47]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 31,  21,  20],\n",
       "         [ 20,  12,  10],\n",
       "         [ 14,   4,   3],\n",
       "         ...,\n",
       "         [ 80,  84,  67],\n",
       "         [ 72,  79,  61],\n",
       "         [ 95, 104,  85]],\n",
       " \n",
       "        [[ 37,  25,  25],\n",
       "         [ 28,  18,  17],\n",
       "         [ 24,  12,  12],\n",
       "         ...,\n",
       "         [ 65,  69,  52],\n",
       "         [ 60,  67,  51],\n",
       "         [ 88,  97,  80]],\n",
       " \n",
       "        [[ 49,  37,  37],\n",
       "         [ 46,  34,  34],\n",
       "         [ 45,  33,  33],\n",
       "         ...,\n",
       "         [ 40,  44,  27],\n",
       "         [ 44,  51,  35],\n",
       "         [ 85,  94,  77]]], dtype=uint8)>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainA': <PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>,\n",
       " 'trainB': <PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>,\n",
       " 'testA': <PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>,\n",
       " 'testB': <PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MapDataset' object has no attribute 'makeOneShotIterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_x\u001b[39m.\u001b[39;49mmakeOneShotIterator()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MapDataset' object has no attribute 'makeOneShotIterator'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billyluqiu/miniforge3/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "epochs = 50\n",
    "\n",
    "LAMBDA = 10\n",
    "\n",
    "img_rows, img_cols, channels = 256, 256, 3\n",
    "weight_initializer = RandomNormal(stddev=0.02)\n",
    "\n",
    "gen_g_optimizer = gen_f_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "dis_x_optimizer = dis_y_optimizer = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images to [-1, 1] and reshape\n",
    "def preprocess_image(image, _):\n",
    "    return tf.reshape(tf.cast(tf.image.resize(image, (int(img_rows), int(img_cols))), tf.float32) / 127.5 - 1, (1, img_rows, img_cols, channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the normalization onto the dataset\n",
    "train_x = train_x.map(preprocess_image)\n",
    "train_y = train_y.map(preprocess_image)\n",
    "test_x = test_x.map(preprocess_image)\n",
    "test_y = test_y.map(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (1, 256, 256, 3), types: tf.float32>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images():\n",
    "    # Sample images\n",
    "    print(test_x)\n",
    "    x = next(iter(test_x.shuffle(1000))).numpy()\n",
    "    y = next(iter(test_y.shuffle(1000))).numpy()\n",
    "    print(x)\n",
    "    # Get predictions for those images\n",
    "    y_hat = generator_g.predict(x.reshape((1, img_rows, img_cols, channels)))\n",
    "    x_hat = generator_f.predict(y.reshape((1, img_rows, img_cols, channels)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (1, 256, 256, 3), types: tf.float32>\n",
      "[[[[-0.56078434 -0.23137254 -0.41960782]\n",
      "   [-0.5686275  -0.27058822 -0.4352941 ]\n",
      "   [-0.7019608  -0.41960782 -0.5294118 ]\n",
      "   ...\n",
      "   [-0.20784312  0.12156868 -0.64705884]\n",
      "   [-0.12156862  0.27058828 -0.41176468]\n",
      "   [-0.19215685  0.05882359 -0.5294118 ]]\n",
      "\n",
      "  [[-0.5058824  -0.17647058 -0.3490196 ]\n",
      "   [-0.5137255  -0.2235294  -0.36470586]\n",
      "   [-0.62352943 -0.35686272 -0.46666664]\n",
      "   ...\n",
      "   [-0.23921567  0.10588241 -0.6392157 ]\n",
      "   [-0.32549018  0.09803927 -0.5764706 ]\n",
      "   [-0.20784312  0.05882359 -0.52156866]]\n",
      "\n",
      "  [[-0.5764706  -0.23921567 -0.38823527]\n",
      "   [-0.5686275  -0.27058822 -0.38823527]\n",
      "   [-0.62352943 -0.36470586 -0.45098037]\n",
      "   ...\n",
      "   [-0.23137254  0.15294123 -0.5686275 ]\n",
      "   [-0.372549    0.05882359 -0.5921569 ]\n",
      "   [-0.11372548  0.1686275  -0.3960784 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.372549   -0.00392157 -0.3490196 ]\n",
      "   [-0.5686275  -0.1607843  -0.4588235 ]\n",
      "   [-0.6313726  -0.17647058 -0.49019605]\n",
      "   ...\n",
      "   [-0.827451   -0.5529412  -0.6       ]\n",
      "   [-0.7647059  -0.4823529  -0.5921569 ]\n",
      "   [-0.75686276 -0.4588235  -0.62352943]]\n",
      "\n",
      "  [[-0.38039213 -0.04313725 -0.38039213]\n",
      "   [-0.60784316 -0.19999999 -0.4823529 ]\n",
      "   [-0.6392157  -0.16862744 -0.4352941 ]\n",
      "   ...\n",
      "   [-0.8117647  -0.5294118  -0.60784316]\n",
      "   [-0.7176471  -0.4352941  -0.54509807]\n",
      "   [-0.70980394 -0.41960782 -0.5529412 ]]\n",
      "\n",
      "  [[-0.26274508  0.05882359 -0.27058822]\n",
      "   [-0.4980392  -0.09803921 -0.35686272]\n",
      "   [-0.5686275  -0.09019607 -0.3490196 ]\n",
      "   ...\n",
      "   [-0.79607844 -0.4980392  -0.6156863 ]\n",
      "   [-0.7176471  -0.4352941  -0.54509807]\n",
      "   [-0.73333335 -0.45098037 -0.56078434]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 22:46:23.990310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-03 22:46:24.845119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_predict_function.<locals>.predict_function at 0x4e992b280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_predict_function.<locals>.predict_function at 0x4e992b280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "generate_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BELOW THIS IS THE TEST DATA FROM KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "images = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"/Users/billyluqiu/Desktop/fall2022/ece588Final/billy/images\", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7038 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "images2 = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"/Users/billyluqiu/Desktop/fall2022/ece588Final/billy/images2\", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = images.map(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = images2.map(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (1, 256, 256, 3), types: tf.float32>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 23:17:36.955437: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for x in test_x:\n",
    "    x_numpy = x.numpy()\n",
    "    y_hat = generator_f.predict(x_numpy.reshape((1, img_rows, img_cols, channels)))\n",
    "    normalizedData = (y_hat[0]-np.min(y_hat[0]))/(np.max(y_hat[0])-np.min(y_hat[0]))\n",
    "\n",
    "    matplotlib.image.imsave('test_images/'+ str(i) + '.png', normalizedData)\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.99967366"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38fe08f3d26a479ec4b53fd1eed47e85ad3eb35a4419302a8faf528c63e8efb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
