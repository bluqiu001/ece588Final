{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3137c9dc",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e076ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9335b25",
   "metadata": {},
   "source": [
    "## Initial Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ac64c1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /proc/cpuinfo: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# number of cpu (in kaggle server)\n",
    "!cat /proc/cpuinfo | grep processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a42e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cpu = 2 # number of cpu threads to use during batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf20adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (path)\n",
    "dataset_name = 'gan-getting-started'\n",
    "root = '../input/'+dataset_name\n",
    "\n",
    "# data (img)\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "channels = 3\n",
    "\n",
    "# training\n",
    "epoch = 0 # epoch to start training from\n",
    "n_epochs = 5 # number of epochs of training\n",
    "batch_size = 1 # size of the batches\n",
    "lr = 0.0002 # adam : learning rate\n",
    "b1 = 0.5 # adam : decay of first order momentum of gradient\n",
    "b2 = 0.999 # adam : decay of first order momentum of gradient\n",
    "decay_epoch = 3 # suggested default : 100 (suggested 'n_epochs' is 200)\n",
    "                 # epoch from which to start lr decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf5a2e5",
   "metadata": {},
   "source": [
    "## Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78053888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "    \n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_block):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "\n",
    "        channels = input_shape[0]\n",
    "\n",
    "        # Initial Convolution Block\n",
    "        out_features = 64\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(channels),\n",
    "            nn.Conv2d(channels, out_features, 7),\n",
    "            nn.InstanceNorm2d(out_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        in_features = out_features\n",
    "\n",
    "        # Downsampling\n",
    "        for _ in range(2):\n",
    "            out_features *= 2\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_block):\n",
    "            model += [ResidualBlock(out_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        for _ in range(2):\n",
    "            out_features //= 2\n",
    "            model += [\n",
    "                nn.Upsample(scale_factor=2),  # --> width*2, heigh*2\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "\n",
    "        # Output Layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(channels),\n",
    "            nn.Conv2d(out_features, channels, 7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        # Unpacking\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22100e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5595,  0.5343],\n",
       "        [-0.4942,  0.4530]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(np.random.randn(2,2))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58942818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5595,  0.5343],\n",
       "          [-0.4942,  0.4530]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.view(1,1,2,2)\n",
    "tensor # nn.Upsample get only 3/4/5D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ec2c5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5595,  0.5595,  0.5343,  0.5343],\n",
       "          [ 0.5595,  0.5595,  0.5343,  0.5343],\n",
       "          [-0.4942, -0.4942,  0.4530,  0.4530],\n",
       "          [-0.4942, -0.4942,  0.4530,  0.4530]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m = nn.Upsample(scale_factor=2)\n",
    "test_m(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fdf47e",
   "metadata": {},
   "source": [
    "## Define Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6134512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        channels, height, width = input_shape\n",
    "        \n",
    "        # Calculate output shape of image discriminator (PatchGAN)\n",
    "        self.output_shape = (1, height//2**4, width//2**4)\n",
    "        \n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128,256),\n",
    "            *discriminator_block(256,512),\n",
    "            nn.ZeroPad2d((1,0,1,0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c66eb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8240, -1.1701],\n",
       "        [ 1.0881,  1.6339]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(np.random.randn(2,2))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "423f3171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.8240, -1.1701],\n",
       "        [ 0.0000,  1.0881,  1.6339]], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m = nn.ZeroPad2d((1,0,0,0)) # Padding_left\n",
    "test_m(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "648c63a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8240, -1.1701,  0.0000],\n",
       "        [ 1.0881,  1.6339,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m = nn.ZeroPad2d((0,1,0,0)) # Padding_right\n",
    "test_m(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65928208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000],\n",
       "        [-0.8240, -1.1701],\n",
       "        [ 1.0881,  1.6339]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m = nn.ZeroPad2d((0,0,1,0)) # Padding_top\n",
    "test_m(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06457c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8240, -1.1701],\n",
       "        [ 1.0881,  1.6339],\n",
       "        [ 0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m = nn.ZeroPad2d((0,0,0,1)) # Padding_bottom\n",
    "test_m(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69103a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.8240, -1.1701],\n",
       "        [ 0.0000,  1.0881,  1.6339]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m = nn.ZeroPad2d((1,0,1,0)) # Padding_left and Padding_top\n",
    "test_m(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc5d5a",
   "metadata": {},
   "source": [
    "### Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbcce068",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41ada9",
   "metadata": {},
   "source": [
    "### Initialize Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95c50e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (channels, img_height, img_width) # (3,256,256)\n",
    "n_residual_blocks = 9 # suggested default, number of residual blocks in generator\n",
    "\n",
    "G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n",
    "G_BA = GeneratorResNet(input_shape, n_residual_blocks)\n",
    "D_A = Discriminator(input_shape)\n",
    "D_B = Discriminator(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0348242",
   "metadata": {},
   "source": [
    "### GPU Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "857ec528",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    G_AB = G_AB.cuda()\n",
    "    G_BA = G_BA.cuda()\n",
    "    D_A = D_A.cuda()\n",
    "    D_B = D_B.cuda()\n",
    "    \n",
    "    criterion_GAN.cuda()\n",
    "    criterion_cycle.cuda()\n",
    "    criterion_identity.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3f148",
   "metadata": {},
   "source": [
    "### Weight Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84a237c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02) # reset Conv2d's weight(tensor) with Gaussian Distribution\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0) # reset Conv2d's bias(tensor) with Constant(0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 1.0, 0.02) # reset BatchNorm2d's weight(tensor) with Gaussian Distribution\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0) # reset BatchNorm2d's bias(tensor) with Constant(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77f0e37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): ZeroPad2d((1, 0, 1, 0))\n",
       "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_AB.apply(weights_init_normal)\n",
    "G_BA.apply(weights_init_normal)\n",
    "D_A.apply(weights_init_normal)\n",
    "D_B.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b38b8bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_weights_init_normal(m):\n",
    "    classname =  m.__class__.__name__\n",
    "    print(classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd16f446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBlock\n",
      "Upsample\n",
      "Conv2d\n",
      "ReLU\n",
      "Upsample\n",
      "Conv2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "Tanh\n",
      "Sequential\n",
      "GeneratorResNet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneratorResNet(\n",
       "  (model): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (18): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (20): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (23): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (27): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_AB.apply(temp_weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "288c0d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_w = torch.ones(2,5)\n",
    "temp_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ede22f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8925,  0.5802,  0.1928, -0.3451, -0.1959],\n",
       "        [-0.5150,  0.2221, -0.1017,  0.5922,  0.0418]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(temp_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe232c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8906,  0.5802,  0.1928, -0.3451, -0.1959],\n",
       "        [-0.5150,  0.2221, -0.1017,  0.5922,  0.0418]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_w2 = torch.empty(2,5)\n",
    "temp_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d77e3be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.constant_(temp_w2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed801c3b",
   "metadata": {},
   "source": [
    "### Configure Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# lr = 0.0002\n",
    "# b1 = 0.5\n",
    "# b2 = 0.999\n",
    "\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1,b2)\n",
    ")\n",
    "\n",
    "optimizer_D_A = torch.optim.Adam(\n",
    "    D_A.parameters(), lr=lr, betas=(b1,b2)\n",
    ")\n",
    "optimizer_D_B = torch.optim.Adam(\n",
    "    D_B.parameters(), lr=lr, betas=(b1,b2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e6c7b",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddd0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLR:\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "        \n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch+self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a1304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_epochs = 10\n",
    "# epoch = 0\n",
    "# decay_epoch = 5\n",
    "\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_G,\n",
    "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
    ")\n",
    "\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_A,\n",
    "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
    ")\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_B,\n",
    "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ca17c",
   "metadata": {},
   "source": [
    "### Image Transformation Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58680b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/lrlqylsx5j1d7jprf6nrcwch0000gn/T/ipykernel_26683/345895398.py:5: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  transforms.Resize(int(img_height*1.12), Image.BICUBIC),\n",
      "/usr/local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transforms_ = [\n",
    "    transforms.Resize(int(img_height*1.12), Image.BICUBIC),\n",
    "    transforms.RandomCrop((img_height, img_width)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3aea05",
   "metadata": {},
   "source": [
    "### DataLoader Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "947c8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(image):\n",
    "    rgb_image = Image.new(\"RGB\", image.size)\n",
    "    rgb_image.paste(image)\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a5ff36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c251805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/gan-getting-started/monet_jpg\n"
     ]
    }
   ],
   "source": [
    "print(root+'/monet_jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "527c9817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(os.path.join(root+'/monet_jpg')+'/*.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "336a89f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(os.path.join(root+'/photo_jpg')+'/*.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cd779a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "            self.files_A = sorted(glob.glob(os.path.join(root+'/monet_jpg')+'/*.*')[:250])\n",
    "            self.files_B = sorted(glob.glob(os.path.join(root+'/photo_jpg')+'/*.*')[:250])\n",
    "        elif self.mode == 'test':\n",
    "            self.files_A = sorted(glob.glob(os.path.join(root+'/monet_jpg')+'/*.*')[250:])\n",
    "            self.files_B = sorted(glob.glob(os.path.join(root+'/photo_jpg')+'/*.*')[250:301])\n",
    "    \n",
    "    def  __getitem__(self, index):\n",
    "        image_A = Image.open(self.files_A[index % len(self.files_A)])\n",
    "        \n",
    "        if self.unaligned:\n",
    "            image_B = Image.open(self.files_B[np.random.randint(0, len(self.files_B)-1)])\n",
    "        else:\n",
    "            image_B = Image.open(self.files_B[index % len(self.files_B)])\n",
    "        if image_A.mode != 'RGB':\n",
    "            image_A = to_rgb(image_A)\n",
    "        if image_B.mode != 'RGB':\n",
    "            image_B = to_rgb(image_B)\n",
    "            \n",
    "        item_A = self.transform(image_A)\n",
    "        item_B = self.transform(image_B)\n",
    "        return {'A':item_A, 'B':item_B}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64b7a7ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mImageDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munaligned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 1\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 3\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m      9\u001b[0m     ImageDataset(root, transforms_\u001b[38;5;241m=\u001b[39mtransforms_, unaligned\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     11\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mn_cpu\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 344\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\n",
    "    ImageDataset(root, transforms_=transforms_, unaligned=True),\n",
    "    batch_size=1, # 1\n",
    "    shuffle=True,\n",
    "    num_workers=n_cpu # 3\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    ImageDataset(root, transforms_=transforms_, unaligned=True, mode='test'),\n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "    num_workers=n_cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28f599",
   "metadata": {},
   "source": [
    "### Define function to get sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40e91893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a1a16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e719952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images():\n",
    "    \"\"\"show a generated sample from the test set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    G_AB.eval()\n",
    "    G_BA.eval()\n",
    "    real_A = imgs['A'].type(Tensor) # A : monet\n",
    "    fake_B = G_AB(real_A).detach()\n",
    "    real_B = imgs['B'].type(Tensor) # B : photo\n",
    "    fake_A = G_BA(real_B).detach()\n",
    "    # Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    real_B = make_grid(real_B, nrow=5, normalize=True)\n",
    "    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n",
    "    # Arange images along y-axis    \n",
    "    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n",
    "    plt.imshow(image_grid.cpu().permute(1,2,0))\n",
    "    plt.title('Real A vs Fake B | Real B vs Fake A')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f67e0064",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m temp_imgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mval_dataloader\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "temp_imgs = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_AB.eval() # test mode \n",
    "G_BA.eval() # test mode\n",
    "print(temp_imgs['A'].shape)\n",
    "print(temp_imgs['B'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_real_A = temp_imgs['A'].type(Tensor) # A : monet\n",
    "temp_fake_B = G_AB(temp_real_A).detach()\n",
    "temp_real_B = temp_imgs['B'].type(Tensor) # B : photo\n",
    "temp_fake_A = G_BA(temp_real_B).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_real_A.shape)\n",
    "print(temp_fake_B.shape)\n",
    "print(temp_real_B.shape)\n",
    "print(temp_fake_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_real_A = make_grid(temp_real_A, nrow=5, normalize=True)\n",
    "temp_real_B = make_grid(temp_real_B, nrow=5, normalize=True)\n",
    "temp_fake_A = make_grid(temp_fake_A, nrow=5, normalize=True)\n",
    "temp_fake_B = make_grid(temp_fake_B, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19827b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp_real_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ceee7ac0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_real_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mtemp_real_A\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal A\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_real_A' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(temp_real_A.cpu().permute(1,2,0))\n",
    "plt.title('Real A')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c4eac41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_real_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtemp_real_A\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(temp_fake_B\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(temp_real_B\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_real_A' is not defined"
     ]
    }
   ],
   "source": [
    "print(temp_real_A.shape)\n",
    "print(temp_fake_B.shape)\n",
    "print(temp_real_B.shape)\n",
    "print(temp_fake_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9309a8e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_real_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m temp_image_grid \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[43mtemp_real_A\u001b[49m, temp_fake_A, temp_real_B, temp_fake_B), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(temp_image_grid\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_real_A' is not defined"
     ]
    }
   ],
   "source": [
    "temp_image_grid = torch.cat((temp_real_A, temp_fake_A, temp_real_B, temp_fake_B), 1)\n",
    "print(temp_image_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef5f977e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_image_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtemp_image_grid\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_image_grid' is not defined"
     ]
    }
   ],
   "source": [
    "temp_image_grid.cpu().permute(1,2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a2ab946",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_image_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mtemp_image_grid\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal A | Fake B | Real B | Fake A \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_image_grid' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(temp_image_grid.cpu().permute(1,2,0))\n",
    "plt.title('Real A | Fake B | Real B | Fake A ')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da936d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epoch, n_epochs):\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        \n",
    "        # Set model input\n",
    "        real_A = batch['A'].type(Tensor)\n",
    "        real_B = batch['B'].type(Tensor)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Tensor(np.ones((real_A.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n",
    "        fake = Tensor(np.zeros((real_A.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n",
    "        \n",
    "# -----------------\n",
    "# Train Generators\n",
    "# -----------------\n",
    "        G_AB.train() # train mode\n",
    "        G_BA.train() # train mode\n",
    "        \n",
    "        optimizer_G.zero_grad() # Integrated optimizer(G_AB, G_BA)\n",
    "        \n",
    "        # Identity Loss\n",
    "        loss_id_A = criterion_identity(G_BA(real_A), real_A) # If you put A into a generator that creates A with B,\n",
    "        loss_id_B = criterion_identity(G_AB(real_B), real_B) # then of course A must come out as it is.\n",
    "                                                             # Taking this into consideration, add an identity loss that simply compares 'A and A' (or 'B and B').\n",
    "        loss_identity = (loss_id_A + loss_id_B)/2\n",
    "        \n",
    "        # GAN Loss\n",
    "        fake_B = G_AB(real_A) # fake_B is fake-photo that generated by real monet-drawing\n",
    "        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid) # tricking the 'fake-B' into 'real-B'\n",
    "        fake_A = G_BA(real_B)\n",
    "        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid) # tricking the 'fake-A' into 'real-A'\n",
    "        \n",
    "        loss_GAN = (loss_GAN_AB + loss_GAN_BA)/2\n",
    "        \n",
    "        # Cycle Loss\n",
    "        recov_A = G_BA(fake_B) # recov_A is fake-monet-drawing that generated by fake-photo\n",
    "        loss_cycle_A = criterion_cycle(recov_A, real_A) # Reduces the difference between the restored image and the real image\n",
    "        recov_B = G_AB(fake_A)\n",
    "        loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
    "        \n",
    "        loss_cycle = (loss_cycle_A + loss_cycle_B)/2\n",
    "        \n",
    "# ------> Total Loss\n",
    "        loss_G = loss_GAN + (10.0*loss_cycle) + (5.0*loss_identity) # multiply suggested weight(default cycle loss weight : 10, default identity loss weight : 5)\n",
    "        \n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "# -----------------\n",
    "# Train Discriminator A\n",
    "# -----------------\n",
    "        optimizer_D_A.zero_grad()\n",
    "    \n",
    "        loss_real = criterion_GAN(D_A(real_A), valid) # train to discriminate real images as real\n",
    "        loss_fake = criterion_GAN(D_A(fake_A.detach()), fake) # train to discriminate fake images as fake\n",
    "        \n",
    "        loss_D_A = (loss_real + loss_fake)/2\n",
    "        \n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "        \n",
    "# -----------------\n",
    "# Train Discriminator B\n",
    "# -----------------\n",
    "        optimizer_D_B.zero_grad()\n",
    "    \n",
    "        loss_real = criterion_GAN(D_B(real_B), valid) # train to discriminate real images as real\n",
    "        loss_fake = criterion_GAN(D_B(fake_B.detach()), fake) # train to discriminate fake images as fake\n",
    "        \n",
    "        loss_D_B = (loss_real + loss_fake)/2\n",
    "        \n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "        \n",
    "# ------> Total Loss\n",
    "        loss_D = (loss_D_A + loss_D_B)/2\n",
    "    \n",
    "# -----------------\n",
    "# Show Progress\n",
    "# -----------------\n",
    "        if (i+1) % 50 == 0:\n",
    "            sample_images()\n",
    "            print('[Epoch %d/%d] [Batch %d/%d] [D loss : %f] [G loss : %f - (adv : %f, cycle : %f, identity : %f)]'\n",
    "                    %(epoch+1,n_epochs,       # [Epoch -]\n",
    "                      i+1,len(dataloader),   # [Batch -]\n",
    "                      loss_D.item(),       # [D loss -]\n",
    "                      loss_G.item(),       # [G loss -]\n",
    "                      loss_GAN.item(),     # [adv -]\n",
    "                      loss_cycle.item(),   # [cycle -]\n",
    "                      loss_identity.item(),# [identity -]\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    print('iter : {}  A.size : {}'.format(i,batch['A'].size()))\n",
    "    print('iter : {}  B.size : {}'.format(i,batch['B'].size()))\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48345196",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_A = batch['A'].type(Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f09db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_img = temp_A.squeeze()\n",
    "temp_img = temp_img.cpu().permute(1,2,0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f94799",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp_img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de44f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_A.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_A.size(0) # batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c574423",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor(np.ones((temp_A.size(0), *D_A.output_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor(np.ones((temp_A.size(0), *D_A.output_shape))).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
